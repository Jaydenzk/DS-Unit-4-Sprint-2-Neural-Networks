{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaydenzk/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Ryp-TVm4njD"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "## Your Mission, should you choose to accept it...\n",
        "\n",
        "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Load the data\n",
        "- Clean the data if necessary (it will be)\n",
        "- Create and fit a baseline Keras MLP model to the data.\n",
        "- Hyperparameter tune (at least) the following parameters:\n",
        " - batch_size\n",
        " - training epochs\n",
        " - optimizer\n",
        " - learning rate (if applicable to optimizer)\n",
        " - momentum (if applicable to optimizer)\n",
        " - activation functions\n",
        " - network weight initialization\n",
        " - dropout regularization\n",
        " - number of neurons in the hidden layer\n",
        " \n",
        " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
        " \n",
        " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfatM6nxoR19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee7f0090-4838-44cd-c02b-e7fd284c6218"
      },
      "source": [
        "pip install wandb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/7b/7d381b5c8345bb5c66bed293281d5c72f173027298e755b2ff2ed9971839/wandb-0.8.12-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Collecting gql>=0.1.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting watchdog>=0.8.3 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 28.5MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.6.1 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting shortuuid>=0.5.0 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Collecting GitPython>=1.0.0 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f8/05f58bd7852dad7edcf70a8de953b4fa39f61cdc13812ae62118be6ffa23/GitPython-3.0.3-py3-none-any.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 40.9MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1 (from wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Collecting sentry-sdk>=0.4.0 (from wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/bb/376c2aa4d7dc03d878efa46d3e43de123c06c6050a500e9596463e65bfad/sentry_sdk-0.12.3-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.9.11)\n",
            "Collecting graphql-core>=0.5.0 (from gql>=0.1.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/11/bc4a7eb440124271289d93e4d208bd07d94196038fabbe2a52435a07d3d3/graphql_core-2.2.1-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
            "Collecting argh>=0.24.1 (from watchdog>=0.8.3->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1 (from watchdog>=0.8.3->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting gitdb2>=2.0.0 (from GitPython>=1.0.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 15.4MB/s \n",
            "\u001b[?25hCollecting rx<3,>=1.6 (from graphql-core>=0.5.0->gql>=0.1.0->wandb)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 56.6MB/s \n",
            "\u001b[?25hCollecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: gql, watchdog, shortuuid, subprocess32, pathtools\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.1.0-cp36-none-any.whl size=5541 sha256=0c616110c0b41a059c9b3f0785498767b36343a5cc7b27fd64895edc138e5b7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=be1b6d2b288f6a03606134ec7f1de1f1a7d727cb94188497e5710938d13aad5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=a2db74c7648a07574f9632b6635e3130b55063a9951bd7b4a27008aa0539f523\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=5703cca703bbbac5e085f99b2b236a85db8bde6d489f7a51c5904c1082748828\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=568d8559db3a881323ad1678d9bcde5b9113f6ab83331b1b7e0dee8e22c2d5cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built gql watchdog shortuuid subprocess32 pathtools\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: rx, graphql-core, gql, docker-pycreds, argh, pathtools, watchdog, python-dateutil, shortuuid, smmap2, gitdb2, GitPython, configparser, subprocess32, sentry-sdk, wandb\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "Successfully installed GitPython-3.0.3 argh-0.26.2 configparser-4.0.2 docker-pycreds-0.4.0 gitdb2-2.0.6 gql-0.1.0 graphql-core-2.2.1 pathtools-0.1.2 python-dateutil-2.8.0 rx-1.6.1 sentry-sdk-0.12.3 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.12 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRguXppNrAZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "c5751661-8abf-4475-d4a2-845f38b68ed8"
      },
      "source": [
        "pip install seed"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seed\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e3/372311673e5f2d24ad191d0d3407b7d3fe476f37a87519ef6ca01f9f3c12/seed-0.11.3.tar.gz (366kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 2.8MB/s \n",
            "\u001b[?25hCollecting path.py<11,>=10 (from seed)\n",
            "  Downloading https://files.pythonhosted.org/packages/82/e5/fc677dd2c835ceaccba4e4730546eda02fd45a47e8c5ea102b560b4cbac3/path.py-10.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from seed) (0.33.6)\n",
            "Building wheels for collected packages: seed\n",
            "  Building wheel for seed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seed: filename=seed-0.11.3-cp36-none-any.whl size=17737 sha256=75e230676831cef4a653972ee7979577de227ac166d9f03e0f30b8f1d7d91812\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/95/b2/554d88be6531ab3a370352a919436c2acb785b940bf6221ec3\n",
            "Successfully built seed\n",
            "Installing collected packages: path.py, seed\n",
            "Successfully installed path.py-10.6 seed-0.11.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNJ-tOBs4jM1",
        "colab": {}
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import wandb\n",
        "import numpy as np\n",
        "import random\n",
        "import seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVURtO-dqY93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVxKjaUqobgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "89ce3785-c0f8-484b-c43c-6ef5581d18ec"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://app.wandb.ai/authorize?signup=true\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: bf2a292a009c2f1eaa2a7e86356b6bb9ccda9ee8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjvr3TLco30l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/Jaydenzk/DS-Unit-4-Sprint-2-Neural-Networks/master/module4-Hyperparameter-Tuning/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VyQrOFcqKDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_encoded = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjtWQN52o3yr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d7478c35-4401-423d-e9a7-0bdaeccdcefd"
      },
      "source": [
        "# Split Data into X and y\n",
        "X = df[['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
        "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n",
        "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
        "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']]\n",
        "\n",
        "y = df['Churn']\n",
        "\n",
        "\n",
        "# Encode Data with LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "X_encoded = X.apply(encoder.fit_transform)\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Add data that didn't need encoded\n",
        "X_encoded['MonthlyCharges'] = df['MonthlyCharges']\n",
        "X_encoded['TotalCharges'] = df['TotalCharges']\n",
        "\n",
        "# Clean the TotalCharges column to replace missing values\n",
        "X_encoded['TotalCharges'] = X_encoded['TotalCharges'].replace(' ', '0')\n",
        "X_encoded['TotalCharges'] = X_encoded['TotalCharges'].astype('float')\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded,\n",
        "                                                    y_encoded,\n",
        "                                                    test_size=0.33)\n",
        "\n",
        "\n",
        "\n",
        "# Create model wrapper\n",
        "def create_model(n_neurons = 20):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add Input Layer\n",
        "  model.add(Dense(n_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "  # Add Hidden Layers\n",
        "  model.add(Dense(n_neurons, activation='relu'))\n",
        "  model.add(Dense(n_neurons, activation='relu'))\n",
        "\n",
        "  # Add Output Layer\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "# Create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# Define the grid search parameters\n",
        "param_grid = {'n_neurons': [15],\n",
        "              'batch_size': [30]}\n",
        "\n",
        "# Create Grid Search\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") \n",
        "\n",
        "# Fit the model\n",
        "# model.fit(X_train, y_train,\n",
        "#           validation_data=(X_test, y_test),\n",
        "#           epochs=wandb.config.epochs,\n",
        "#           batch_size=wandb.config.batch_size,\n",
        "#           callbacks=[WandbCallback()])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.7132259461524982 using {'batch_size': 30, 'n_neurons': 15}\n",
            "Means: 0.7132259461524982, Stdev: 0.033157044368083935 with: {'batch_size': 30, 'n_neurons': 15}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fPnfPCeo3tF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9X-R50do3q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfZRtJ7MCN3x"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
        "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
        "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
        "- Study for the Sprint Challenge\n",
        " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
        " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
      ]
    }
  ]
}